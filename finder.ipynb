{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 198-199: truncated \\uXXXX escape (<ipython-input-58-afb869174712>, line 10)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-58-afb869174712>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 198-199: truncated \\uXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@misc{MobilNet_SSD_opencv,\n",
    "  title={MobilNet_SSD for object detection on Keras and TensorFlow},\n",
    "  author={djmv},\n",
    "  year={2018},\n",
    "  publisher={Github},\n",
    "  journal={GitHub repository},\n",
    "  howpublished={\\url{https://github.com/djmv/MobilNet_SSD_opencv.git}},\n",
    "  }\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Import the neccesary libraries\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 \n",
    "from gtts import gTTS\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels of Network.\n",
    "classNames = { 'background':0,\n",
    "    'aeroplane':1, 'bicycle':2 , 'bird': 3, 'boat':4,\n",
    "    'bottle':5, 'bus':6, 'car':7, 'cat':8, 'chair':9,\n",
    "    'cow':10, 'diningtable':11,  'dog':12,  'horse':13,\n",
    "    'motorbike':14, 'person':15, 'pottedplant':16,\n",
    "    'sheep':17, 'sofa':18, 'train':20,  'tvmonitor':20 }\n",
    "    \n",
    "\n",
    "#Load the Caffe model \n",
    "net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt', 'MobileNetSSD_deploy.caffemodel')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = sys.argv[1]\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "cap= cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object to Detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voice to text and Voice assistance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Initialize recognizer class (for recognizing the speech)\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Reading Microphone as source\n",
    "# listening the speech and store in audio_text variable\n",
    "def talk():\n",
    "    with sr.Microphone() as source:\n",
    "        what=\"what are you loking for, give me one word\"\n",
    "        file = \"what.mp3\"\n",
    "        # initialize tts, create mp3 and play\n",
    "        #tts = gTTS(what)\n",
    "        #tts.save(file)\n",
    "        os.system(\"mpg123 \" + file)\n",
    "        playsound(file)\n",
    "        \n",
    "        audio_text = r.listen(source)\n",
    "        print(\"Time over, thanks\")\n",
    "    # recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
    "        try:\n",
    "            # using google speech recognition\n",
    "            text=r.recognize_google(audio_text, language = 'en')\n",
    "            print(text)\n",
    "            if text in classNames:\n",
    "                scan=\"Scan the room\"\n",
    "                file = \"scan.mp3\"\n",
    "                # initialize tts, create mp3 and play\n",
    "                tts = gTTS(scan)\n",
    "                tts.save(file)\n",
    "                os.system(\"mpg123 \" + file)\n",
    "                playsound(file)\n",
    "                return text\n",
    "                \n",
    "            else:\n",
    "                err2='sorry I was not trained'\n",
    "                file = \"err1.mp3\"\n",
    "                # initialize tts, create mp3 and play\n",
    "                tts = gTTS(err2)\n",
    "                tts.save(file)\n",
    "                os.system(\"mpg123 \" + file)\n",
    "                playsound(file)\n",
    "        except:\n",
    "                err2=\"sorry i did not get that\"\n",
    "                file = \"err2.mp3\"\n",
    "                # initialize tts, create mp3 and play\n",
    "                #tts = gTTS(err2)\n",
    "                #tts.save(file)\n",
    "                os.system(\"mpg123 \" + file)\n",
    "                playsound(file)\n",
    "talk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note if the voice voice to txt ain't woking propaly declear the var find manually i.e find='bottle'\n",
    "\n",
    "find='bottle'   # or find = talk()\n",
    "find_id=classNames[find]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "go left\nstop\nstop\nstop\ngo down\ngo left\ngo right\ngo down\ngo left\ngo up\ngo right\nstop\nstop\nstop\nstop\nstop\nstop\ngo left\nstop\nstop\nstop\nstop\ngo left\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\ngo left\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\nstop\ngo down\ngo left\ngo right\ngo down\ngo right\n"
    }
   ],
   "source": [
    "left=True\n",
    "down= True\n",
    "up=True\n",
    "right=True\n",
    "cascPath = sys.argv[1]\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "cap= cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    frame_resized = cv2.resize(frame,(300,300)) # resize frame for prediction\n",
    "\n",
    "    # MobileNet requires fixed dimensions for input image(s)\n",
    "    # so we have to ensure that it is resized to 300x300 pixels.\n",
    "    # set a scale factor to image because network the objects has differents size. \n",
    "    # We perform a mean subtraction (127.5, 127.5, 127.5) to normalize the input;\n",
    "    # after executing this command our \"blob\" now has the shape:\n",
    "    # (1, 3, 300, 300)\n",
    "    blob = cv2.dnn.blobFromImage(frame_resized, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "    #Set to network the input blob \n",
    "    net.setInput(blob)\n",
    "    #Prediction of network\n",
    "    detections = net.forward()\n",
    "\n",
    "    #Size of frame resize (300x300)\n",
    "    cols = frame_resized.shape[1] \n",
    "    rows = frame_resized.shape[0]\n",
    "\n",
    "    #For get the class and location of object detected, \n",
    "    # There is a fix index for class, location and confidence\n",
    "    # value in @detections array .\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2] #Confidence of prediction\n",
    "\n",
    "        if confidence > 0.75: #Filter prediction \n",
    "            class_id = int(detections[0, 0, i, 1]) #Class label\n",
    "            if  class_id == find_id:\n",
    "\n",
    "                # Object location \n",
    "                xLeftBottom = int(detections[0, 0, i, 3] * cols) \n",
    "                yLeftBottom = int(detections[0, 0, i, 4] * rows)\n",
    "                xRightTop   = int(detections[0, 0, i, 5] * cols)\n",
    "                yRightTop   = int(detections[0, 0, i, 6] * rows)\n",
    "\n",
    "                # Centre\n",
    "                xcentre=int((xRightTop+xLeftBottom)/2) \n",
    "                ycentre=int((yRightTop+yLeftBottom)/2)\n",
    "\n",
    "                # Draw location of central square\n",
    "                x_b= int((cols/2)-20) \n",
    "                x_t= int((cols/2)+20)\n",
    "                y_r= int((rows/2)+20)\n",
    "                y_l= int((rows/2)-20)\n",
    "\n",
    "                frame_resized= cv2.rectangle(frame_resized, (x_t, y_l), (x_b, y_r),(0, 255, 0))\n",
    "\n",
    "                # Draw location of object\n",
    "                frame_resized= cv2.rectangle(frame_resized, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop),(0, 255, 0))\n",
    "\n",
    "                # Direction\n",
    "                if xcentre > x_t or xcentre < x_b:\n",
    "                    if xcentre > x_t and right: \n",
    "                        right= False\n",
    "                        left=True\n",
    "                        up=True\n",
    "                        down=True\n",
    "                        print('go right')\n",
    "                        break\n",
    "    \n",
    "                    if xcentre < x_b and left:\n",
    "                        left= False\n",
    "                        right=True\n",
    "                        up=True\n",
    "                        down=True\n",
    "                        print('go left')\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "                if ycentre > y_r or ycentre < y_l:\n",
    "                    if ycentre < y_l and up:\n",
    "                        up= False\n",
    "                        left=True\n",
    "                        right=True\n",
    "                        down=True\n",
    "                        print('go up')\n",
    "                        break\n",
    "        \n",
    "                    if ycentre > y_r and down:\n",
    "                        down= False\n",
    "                        up=True\n",
    "                        left=True\n",
    "                        right=True\n",
    "\n",
    "            \n",
    "                        print('go down')\n",
    "                        break\n",
    "                    break\n",
    "\n",
    "                if ycentre < y_r and ycentre > y_l and  xcentre < x_t and xcentre > x_b:\n",
    "                    #rest\n",
    "                    left=True\n",
    "                    right=True\n",
    "                    up=True\n",
    "                    down=True\n",
    "                    print('stop')\n",
    "                \n",
    "                break #Print class and confidence\n",
    "                               \n",
    "    #cv2.namedWindow(\"frame\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"frame\", frame_resized)\n",
    "    if cv2.waitKey(1) >= 0:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()  # Break with ESC \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbaseconda88059e61bdb94071ac24b48829acc08a",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}